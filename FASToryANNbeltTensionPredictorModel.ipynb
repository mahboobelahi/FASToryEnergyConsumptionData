{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data for Traning, Cross Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly selecting \"n\" records for testing\n",
    "#this unseen data will be used for assessing ANN model once it is trained, tested and validated \n",
    "def select_random(df,num,file_name):\n",
    "      # for random indices\n",
    "    index = np.random.choice(df.shape[0], num, replace=False) \n",
    "    df_500= df.iloc[index]\n",
    "    #df.drop(index,inplace=True)\n",
    "    df_500.to_csv(file_name.split('_')[0]+\"_TestData.csv\",index=False)\n",
    "    df.to_csv(file_name.split('_')[0]+\"_TraningData.csv\",index=False)\n",
    "\n",
    "file_name = \"./data/ProcessedStaticCaseData/FASToryPowerConsumptionData_Processed.csv\"\n",
    "df= pd.read_csv(file_name.split('_')[0]+\"_Processed.csv\")\n",
    "select_random(df,500,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history_dict,i):\n",
    "    \n",
    "    sns.set(style='whitegrid')#plt.style.use('fivethirtyeight')\n",
    "    plt.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "    \n",
    "    acc_values = history_dict['accuracy']\n",
    "    val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc_values, 'bo', label=\"Training Accuracy\")\n",
    "    plt.plot(epochs, val_acc_values, 'r', label=\"Validation Accuracy\")\n",
    "\n",
    "    plt.title(f'Training and Validation Accuraccy_{i}')\n",
    "    plt.yticks(np.arange(0,1.2,0.1))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    #uncomment following line if you want ot save model accuracy plot\n",
    "    #plt.savefig(f'T_V_Validation_{i}.png',bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_loss(history_dict,i):\n",
    "    \n",
    "    sns.set(style='whitegrid')#plt.style.use('fivethirtyeight')\n",
    "    plt.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "    \n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    plt.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "    plt.plot(epochs, loss_values, 'ro', label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss_values, 'b', label=\"Validation Loss\")\n",
    "    plt.yticks(np.arange(0,1.2,0.1))\n",
    "    plt.title(f'Training and Validation Loss_{i}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.legend()\n",
    "    #plt.savefig(f'T_V_Loss_{i}.png',bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df,features):\n",
    "    \n",
    "\n",
    "    one_hot_encode = to_categorical(df['Class_3'])\n",
    "    print('HERERRR\\n',one_hot_encode)\n",
    "\n",
    "    X=np.array(df[features])\n",
    "    type(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,one_hot_encode, test_size=0.33, random_state=42)\n",
    "\n",
    "    X_train= np.array(X_train)\n",
    "    X_test= np.array(X_test)\n",
    "\n",
    "    print(f'{type(X_train)} ,{X_train.shape}, {type(X_train)} , {X_test.shape}')\n",
    "    print(f'{type(y_train)} ,{y_train.shape}, {type(y_train)},{y_test.shape}')\n",
    "\n",
    "    return {\"TT_split\":( X_train, X_test, y_train, y_test)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(model_architecture=[10,10,10,10]):\n",
    "    \n",
    "    #build model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(model_architecture[0], input_dim=2, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(model_architecture[1], activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(model_architecture[2], activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(model_architecture[3], activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model,split,i,epocs=100):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= split.get(\"TT_split\")\n",
    "    # fit model\n",
    "    history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=epocs,\n",
    "                   batch_size=10,\n",
    "                   validation_data=(X_test, y_test))\n",
    "    \n",
    "\n",
    "    model.save(f'./ANNmodel/M_iter3_{i}.h5') #using h5 extension\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belt Tension Evaluation and Prediction for unseen test data (500 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prdict_Tension_class(model,i,features,T_class=3):\n",
    "    \n",
    "    df_test= pd.read_csv('./data/ProcessedStaticCaseData/FASToryPowerConsumptionData_TestData.csv')\n",
    "    #index for 100 samples between 0-500\n",
    "    nn=np.random.randint(500, size=100)\n",
    "    X_Test= np.array(df_test[features])   \n",
    "    y_Test=np.array(to_categorical(df_test[f'Class_{T_class}']))\n",
    "    results = model.evaluate(X_Test, y_Test)\n",
    "    \n",
    "    #class prediction\n",
    "    pred = model.predict(X_Test[nn]) \n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "    True_label = np.argmax(y_Test[nn],axis = 1)\n",
    "    accuracy_score( True_label,pred )\n",
    "    \n",
    "    load = df_test['Load Combinations'][nn]\n",
    "    power = df_test['Power (W)'][nn]\n",
    "    \n",
    "    #uncomment following line if want to save predections in csv file\n",
    "    # tem_df=df_test.loc[nn,['Load Combinations','Power (W)','%Belt Tension',f'Class_{T_class}']]\n",
    "    # tem_df['Pred_BT_Class'] = pred\n",
    "    # tem_df.to_csv(f'./ModelPredections/pred{T_class}_{i}.csv',index=False)\n",
    "    \n",
    "    return (T_class,results[0],results[1],pred,True_label,load,power)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Block: All Functions are called in this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# holds test data evaluation and predicted belt tension class \n",
    "cashe ={} # printing Average Loss and Accuracy\n",
    "\n",
    "# reading trainiing data file\n",
    "df_train= pd.read_csv(\"./data/ProcessedStaticCaseData/FASToryPowerConsumptionData_TraningData.csv\")\n",
    "T_class = 3\n",
    "epocs = 150\n",
    "features= ['Normalized_Power','Normalized_Load']\n",
    "\n",
    "# list contains number of hidden and output layer nodes\n",
    "model_architecture = [10,10,6,4]\n",
    "#if isinstance(split.get(\"TT_split\"),tuple):\n",
    "    \n",
    "# build and compile model\n",
    "model = NN_model(model_architecture)\n",
    "    \n",
    "\"\"\"\n",
    "    For loop for getting average loss and accuracy\n",
    "\"\"\"\n",
    "for i in range(1):\n",
    "\n",
    "    # spliting the data into train-test data \n",
    "    print(f'Splitting data {i+1}.\\n')\n",
    "\n",
    "    split = train_test(df_train,features)\n",
    "    #X_train, X_test, y_train, y_test= split.get(\"TT_split\")\n",
    "    if isinstance(split.get(\"TT_split\"),tuple):\n",
    "        # fit model\n",
    "        history = fit_model(model,split,i+1,epocs)\n",
    "\n",
    "        # getting loss and accuracy for training and validation data\n",
    "        history_dict = history.history\n",
    "        print(history_dict.keys())\n",
    "\n",
    "        # Plotting losses \n",
    "        #plot_loss(history_dict,i+1)\n",
    "\n",
    "        # Training and Validation Accuracy\n",
    "        #plot_accuracy(history_dict,i+1)\n",
    "\n",
    "        res = prdict_Tension_class(model,i+1,features,T_class)\n",
    "\n",
    "\n",
    "        if f'class_{T_class}' not in cashe:\n",
    "\n",
    "            cashe[f'class_{T_class}'] = dict(\n",
    "                            [('loss',[res[1]]), ('accuracy',[res[2]]),\n",
    "                            ('true_classes',[res[3]]),('pred_classes', [res[4]]),\n",
    "                             ('load',[res[5]]),('power',[res[6]])]\n",
    "                             )\n",
    "        else:\n",
    "            temp = cashe.get(f'class_{T_class}')\n",
    "            temp['loss'].append(res[1])\n",
    "            temp['accuracy'].append(res[2])\n",
    "            temp['true_classes'].append(res[3])\n",
    "            temp['pred_classes'].append(res[4])\n",
    "            temp['load'].append(res[5])\n",
    "            temp['power'].append(res[6])\n",
    "            #(T_class,results[0],results[1],True_label,pred,load,power)\n",
    "    \n",
    "    else:\n",
    "        print(split.get(\"TT_split\"))\n",
    "        #print(prdict_Tension_class(1))\n",
    "        \n",
    "#print(cashe.get(f'class_{T_class}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "y_test=[]\n",
    "y_predicted =[]\n",
    "for i in range(1,10):\n",
    "    df= pd.read_csv(f\"./data/ModelPredections/pred3_{i}.csv\")\n",
    "    y_test.extend(df[\"Class_3\"].to_list())\n",
    "    y_predicted.extend(df[\"Pred_BT_Class\"].to_list())\n",
    "print(f\"Test: {len(y_test)}\")\n",
    "print(f\"Pred: {len(y_predicted)}\")\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Class1','Class2','Class3'], \n",
    "                     columns = ['Class1','Class2','Class3'])\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.tight_layout()\n",
    "\n",
    "group_names=[\"(cell 1)\",\"(cell 2)\",\"(cell 3)\",\n",
    "        \"(cell 4)\",\"(cell 5)\",\"(cell 6)\",\n",
    "        \"(cell 7)\",\"(cell 8)\",\"(cell 9)\"]\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "          zip(group_counts,group_names)]\n",
    "labels = np.asarray(labels).reshape(3,3)\n",
    "sns.set(style='white')\n",
    "sns.set(font_scale=2.5) # Adjust to fit text in cell\n",
    "sns.heatmap(cm_df, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "plt.ylabel('Actual Belt Tension Class',fontsize=15)\n",
    "plt.xlabel('Predicted Belt Tension Class',fontsize=15)\n",
    "plt.savefig('confusionMat.png', dpi=500)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fe682157fb9fbdc2d281994f7ea65b67a3b9cfb4d7e9aae0f525c1bb50293be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
